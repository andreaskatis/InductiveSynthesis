\newcommand{\realizable}{\textsc{realizable}}
\newcommand{\unrealizable}{\textsc{unrealizable}}
\newcommand{\skolems}{\textit{Skolems}}
\newcommand{\isValid}{\textsc{isValid}\xspace}
\newcommand{\isInvalid}{\textsc{isInvalid}\xspace}
% \newcommand{\synthesisalgorithm}{
% \begin{algorithm2e}[H]
% \SetAlFnt{\tiny}
% \SetAlCapFnt{\small}
% \SetAlCapNameFnt{\small}
% \SetAlgoSkip{}
% \SetKwFor{While}{forever}{do}{}
% \SetKw{KwContinue}{continue}
% \KwIn{Assume-Guarantee Contract in Lustre, $(A,G)$}
% \KwOut{Skolem collection \skolems, \\ \hspace{+1.3cm} Return value $\in
% \{\realizable, \unrealizable\}$ of ${(A,G)}$.
% }
% \BlankLine
% $i \gets 0$;\\
% $BaseResult \gets \textsc{BaseCheckEngine.\aeval}(BaseCheck(i))$\;
% $ExtendResult \gets \textsc{ExtendCheckEngine.\aeval}(ExtendCheck(i))$;
% \\
% \While{}{	
% 	\uIf(\label{alg:returnUnsat}){(\textsc{BaseCheckEngine}.\isValid($BaseResult$))}
% 	{
% 		\Return
% 		\unrealizable 
% 	}
% 	$Skolems.Add(BaseResult.Skolem)$;\\
% 	\uIf(\label{alg:returnSat}){$(\textsc{ExtendCheckEngine}.\isInvalid($ExtendResult$))$}
% 	{
% 		$Skolems.Add((ExtendResult.Skolem))$;\\
% 		\Return \skolems, \realizable
% 	}
% 	$i$++;
% }
% \caption{Synthesis from Assume-Guarantee Contracts}
% \label{alg:synthesis}
% \end{algorithm2e}
% }


\section{Synthesis from Assume-Guarantee Contracts}
\label{sec:synthesis}

%GRIGORY: no need to repeat the things since they all are mentioned in the intro (a couple of paragraphs above)
%
In this section we provide %a summary of the formal background
%that has already been established in previous work, regarding an algorithm that
%is able to generate leaf-level component implementations using only the
%information provided by the user through requirements expressed in the form of an
%Assume-Guarantee contract. Our approach supports the Linear Real
%Arithmetic (LRA) theory.
%mainly due to the limitations imposed by the underlying machinery.
% We begin with 
a brief background on Assume-Guarantee contracts, 
proceed with summarizing our earlier results on realizability
checking of contracts, and finally
present our program synthesis procedure.
%Finally, we enrich our formal definitions with an informal proof of the
%algorithm's correctness in terms of the successfully synthesized
%implementations.

\subsection{Assume-Guarantee Contracts}

One of the most popular ways to describe requirements during the development
cycle of software, is through the notion of an Assume-Guarantee contract, where
the requirements are expressed using safety properties that are split into two separate categories. The
\emph{assumptions} of the contract correspond to properties that restrict the
set of valid inputs a system can process, while the \emph{guarantees} dictate
how the system should behave, using properties that precisely describe
the kinds of valid outputs that it may return to its environment.

As an illustrative example, consider the contract with the assumption $A =
\{x\neq y\}$ and the guarantee $G = \{\text{if } x \leq y \text{ then } z =
\textit{ true } \text{else } z  = \textit{false}\}$.
The component to be designed consists of two inputs, $x$ and $y$ and one output $z$. If we restrict our example to the case of integer arithmetic,
we can see that the contract assumes that the inputs will never have the same value,
and requires that the output of the component is Boolean 
whose value depends on the comparison of the values of $x$ and $y$.
At this point, it is crucial to notice that we have not discussed anything
regarding the implementation. This is due to the fact that, during the
early stages of software development, the implementation is absent or exists only partially.

Deciding existence of an implementation 
that satisfies the specific contract for all possible inputs is aimed by the problem of 
\emph{realizability}, while automatically constructing a witness  of the proof 
of realizability of the contract is aimed by problem of \emph{program synthesis}.
The contract $(A,G)$ above is obviously
\emph{realizable}, and therefore an implementation exists for the specific
component.
Interestingly, if the assumption would be omitted then 
the contract is clearly \emph{unrealizable}, since no implementation 
is able to provide a correct output in the case where $x=y$.

\subsection{Formal Preliminaries}
\label{sec:pre}

For the purposes of this paper, we describe a system using the types
$state$ and $inputs$. Formally, an \emph{implementation}, i.e. a
\emph{transition system} can be described using a set of initial states $I(s)$ of type $state \implies bool$, in addition to a transition relation $T(s,i,s')$ that
implements the contract and has type $state \implies inputs \implies
state \implies bool$.
 
An Assume-Guarantee (AG) contract can be formally defined by two sets, a set of
\emph{assumptions} and a set of \emph{guarantees}. The \emph{assumptions} $A$
impose constraints over the inputs, while the \emph{guarantees} $G$ are used for
the corresponding constraints over the outputs of the system and can be expressed as
two separate subsets $G_I$ and $G_T$, where $G_I$ defines the set of valid
initial states, and $G_T$ specifies the properties that need to be met during
each new transition between two states. Note that we do not necessarily expect
that a contract would be defined over all variables in the transition system,
but we do not make any distinction between internal state variables and outputs in the formalism.
This way, we can use state variables to, in some cases, simplify statements of guarantees.

\subsection{Realizability of Contracts}
The synthesis algorithm proposed in this paper is built on top of our realizability algorithm
originally presented in~\cite{Katis15:Realizability}. Using the formal foundations described in Sect.~\ref{sec:pre},
the problem of realizability is expressed using the notion of a state being \emph{extendable}:

\begin{definition}[One-step extension]
\label{def:extend}
A state $s$ is extendable after $n$ steps, denoted $\mathit{Extend}_{n}(s)$, if
any valid path of length $n-1$ starting from $s$ can be extended in response to
any input.%
%
\begin{multline*}%
\mathit{Extend}_{n}(s) \triangleq \forall i_1, s_1, \ldots, i_n, s_n.\\ A(s, i_1) \land G_T(s, i_1, s_1)
\land \cdots \land
A(s_{n-1}, i_n) \land G_T(s_{n-1}, i_n, s_n)
\implies \\
\forall i.~ A(s_n, i) \implies \exists s'.~ G_T(s_n, i, s')
\end{multline*}
\end{definition}

The algorithm for realizability uses Def.~\ref{def:extend} in two
separate checks that correspond to the two traditional cases exercised in
k-induction. For the $\mathit{BaseCheck}$, we ensure that all initial states are
extendable in terms of any path of length $k\le n$, while the inductive step of
$\mathit{ExtendCheck}$ tries to prove that all valid states are extendable.
Therefore, we attempt to find the smallest $n$, for which the two following 
$\forall\exists$-formulas are valid:%
%
\begin{equation}
\label{eq:sbcheck}
\mathit{BaseCheck}(n) \triangleq \forall k \leq n. (\forall s. G_I(s)
	  	\implies \mathit{Extend}_k(s))
\end{equation}%
%
\begin{equation}
\label{eq:echeck}
\mathit{ExtendCheck}(n) \triangleq \forall s. \mathit{Extend}_n(s)
\end{equation}

The realizability checking algorithm has been used to effectively find cases
where the traditional consistency check (i.e. the existence of an assignment
to the input variables for which the output variables satisfy the contract)
failed to detect conflicts between stated requirements in case studies of
different complexity and importance. It has also been formally verified using the Coq proof assistant in terms of its
soundness, for the cases where it reports that a contract is
realizable~\cite{katis2015machine}.

\subsection{Program Synthesis from Proofs of Realizability}

%While the implemented algorithm on realizability provided us with meaningful
%results during the verification of several contracts, 
The most important outcome of our previous work on realizability is that it 
 can be further used for solving the more complex problem of
\emph{program synthesis} i.e., to automatically
derive implementations, from the proof of the contract's
realizability.
%The limited power of SMT solvers
%in terms of solving formulas containing nested quantifiers immediately ruled
%out the prospect of using one as our primary synthesis tool. Fortunately, 
%we are able to exploit our prior results in the scope of solving validity and 
%Skolemizing $\forall\exists$-formulas (to be described in Sect.~\ref{sec:aeval}).

The idea behind our approach to solving the synthesis problem is
simple and elegant. Consider checks~\eqref{eq:sbcheck} and~\eqref{eq:echeck} that
are used in the realizability checking algorithm. Both checks require
that the reachable states explored are extendable using
Def.~\ref{def:extend}.
The key insight then is to decide if $\mathit{Extend}_{n}(s)$ is valid and generate a witness 
for each of the $n$ times that we run $\mathit{BaseCheck}$ and a final witness 
for the inductive case in $\mathit{ExtendCheck}$.

In the first order logic, witnesses for valid $\forall\exists$-formulas are represented by the Skolem functions.
Intuitively, a Skolem function expresses a connection between all universally quantified variables in the left-hand-side of the $\forall\exists$-formulas~\eqref{eq:sbcheck} and~\eqref{eq:echeck} and the existentially quantified variable $s'$ in the right-hand-side of the the formulas.
Our algorithm automatically generates such Skolem functions
while solving the validity of~\eqref{eq:sbcheck} and~\eqref{eq:echeck} and is described in details Sect.~\ref{sec:aeval}.

%\synthesisalgorithm

Algorithm~\ref{alg:synthesis} provides a summary of the synthesis procedure,
showing how it naturally extends our previous work on realizability checking.
During the k-induction algorithm, two parallel engines (\textsc{BaseEngine,
ExtendEngine}) correspondingly handle the base and inductive step checks of
validity of $\forall\exists$-formulas. The proof of a formula's validity is
closely tied to the process of Skolemization. As a result, every step for which
the \textit{BaseCheck(n)} is valid according to \aeval, we also receive a Skolem function
that can be used as a witness that satisfies the formula. We keep repeating this
process, accumulating Skolem functions as long as the corresponding \textit{BaseCheck(n)}
is valid. As soon as the inductive step of \textit{ExtendCheck(n)} passes, we
have a complete k-inductive proof stating that the contract is realizable. We then complete our synthesis
procedure by generating a Skolem function that corresponds to the inductive
step, and return the collection of the Skolem functions to the user.

\begin{figure}
\begin{minipage}[t]{0.65\textwidth}
    \scalebox{0.9}{
\begin{algorithm2e}[H]
\SetAlgoSkip{}
\SetKwFor{While}{forever}{do}{}
\SetKw{KwContinue}{continue}
\KwIn{AG-Contract in Lustre, $(A,G)$}
\KwOut{Return value
$\in \{\realizable, \unrealizable\}$, Skolem collection \skolems
}
\BlankLine
$i \gets 0$;\\
\grigory{Something is wrong here. The counter $i$ is incremented in the loop, but used only outside of the loop.\\}
$BaseResult \gets \textsc{BaseEngine.\aeval}(BaseCheck(i))$\;
$ExtendResult \gets \textsc{ExtendEngine.\aeval}(ExtendCheck(i))$;
\\
\While{}{	
	\lIf(\label{alg:returnUnsat}){$(\textsc{BaseEngine}.\isValid(BaseResult))$}
	{%
		\Return
		\unrealizable, $\varnothing$%
	}
	$Skolems.Add(BaseResult.Skolem)$;\\
	\uIf(\label{alg:returnSat}){$(\textsc{ExtendEngine}.\isInvalid($ExtendResult$))$}
	{
		$Skolems.Add((ExtendResult.Skolem))$;\\
		\Return \realizable, \skolems;
	}
	$i$++;
}
\caption{Synthesis from AG-Contracts}
\label{alg:synthesis}
\end{algorithm2e}}
\end{minipage}
\begin{minipage}[t]{0.33\textwidth}
\scalebox{.9}{
\begin{algorithm2e}[H]
\SetAlgoSkip{}
\SetKwFor{While}{forever}{do}{}
\BlankLine
  \textsc{assign\_$G_{I}$\_\textsc{witness()}};

\BlankLine
  \textsc{read\_inputs()}; 		
  \textsc{Skolems[0]()}\;
  $\ldots$\\
  \textsc{read\_inputs()}\;
  \textsc{Skolems[k-1]()}\;
  
\BlankLine  

\While{}{  
 \textsc{read\_inputs()}; 		
 \textsc{Skolems[k]()}\;
 \textsc{update\_history()}\;%
}

\caption{Structure of implementations.}
\label{alg:synt}
\end{algorithm2e}}
\end{minipage}
\caption{Synthesis algorithm and structure of implementations}
\end{figure}

Finally, the implementation of the contract can be realized by plugging these Skolem functions into the implementation skeleton 
shown in Alg.~\ref{alg:synt}. One of the direct effects of using Lustre in
conjunction with a k-inductive proof is that we can have properties in the model
that refer to up to a previous value of a variable, up to $k-1$ steps in the
past. As such, the implementation begins (method
\textsc{assign\_$G_{I}$\_witness()}) by creating an array for each state
variable up to depth $k$, where $k$ is the depth at which we found a solution to our realizability algorithm.
In each array, the $i$-th element, with $0\leq i \leq k$, corresponds to the
value assigned to the variable after the call to $i$-th Skolem function. As
such, the $k-1$ elements of each array correspond to the $k-1$ Skolem
functions produced by the $\mathit{BaseCheck}$ process, while the last element
is used by the Skolem function generated from the formula corresponding to
the $\mathit{ExtendCheck}$ process.

The algorithm then uses the Skolem functions generated by \aeval for each
of the $\mathit{BaseCheck}$ instances to describe the initial behavior of
the implementation up to depth $k$.  This process starts from the memory-free
description of the initial state ($G_I$). 
There are two ``helper'' operations:
\textsc{update\_history()} shifts each element in the arrays one position
forward (the $(0)$'th value is simply forgotten), and \textsc{read\_inputs()} reads the
current values of inputs into the $i$-th element of the input variable arrays,
where $i$ represents the $i$-th step of the process.
Once the history is entirely initialized using the $\mathit{BaseCheck}$ witness values,
we add the Skolem function that represents the witness for the
$\mathit{ExtendCheck}$ instance to describe the recurrent behavior of the implementation, i.e.,
the next value of outputs in each iteration in the infinite loop.

Finally, to further strengthen our claims regarding the algorithm's
correctness, we wrote machine-checked proofs regarding the validity of \textit{BaseCheck(n)} and
\textit{ExtendCheck(n)}, when Skolem functions are used as witness states
towards synthesizing the implementations. The entirety of the models explored in
this paper only involved proofs of realizability of length $k$ equal to 0 or
1%
\footnote{The proofs can be found at \url{https://github.com/andrewkatis/Coq}.}.
As such, we limited our proofs of soundness to these two specific cases. We hope
to extend the proofs to capture any arbitrary $k$ as part of our future work.
The theorems were written and proved using the Coq proof
assistant~\cite{Coqmanual}.

\begin{theorem}[Bounded Soundness of BaseCheck and ExtendCheck using Skolem
Functions] Let $BaseCheck_{Skolem_n}(n)$ and
$ExtendCheck_{Skolem_n}(n)$, $n \in {0,1}$ be the valid
variations of the corresponding formulas \textit{BaseCheck(n)} and
\textit{ExtendCheck(n)}, where the existentially quantified part has been substituted
with a witnessing Skolem function. We have that:
\begin{itemize}
\item $\forall (A,G_{I},G{T}). BaseCheck(n) \Rightarrow BaseCheck_{Skolem_n}(n)$
\item $\forall (A,G_{I},G{T}). ExtendCheck(n) \Rightarrow
ExtendCheck_{Skolem_n}(n)$
\end{itemize}
\end{theorem}
\begin{proof}
The proof uses the definition \textit{$Extend_n(s)$} of an extendable state,
after replacing the next-step states with corresponding Skolem functions. From there,
the proof of the two implications is straightforward.
\qed
\end{proof}

 \subsection{Running Example} 
 
 Fig.~\ref{fg:example} shows a
 simple but yet representative example to our approach.
 This is the set of requirements  in the Lustre language and an automaton satisfying these requirements.
 There is an input variable \texttt{x} (used as an argument to the \texttt{--\%REALIZABLE} query) and an output variable \texttt{state}.
 %GRIGORY: I think, it is pretty clear:
 %we use a simple hack that prevents us from explicitly defining how it should
 %be assigned, by adding it as an actual input to the specification.
 %
 There are five properties.
 Properties \texttt{prop2} and \texttt{prop3} are used to indirectly describe some
 possible transitions in the automaton. Properties \texttt{prop1} and
 \texttt{prop4} are the requirements with respect to two local variables, \texttt{bias}
 and \texttt{bias\char`_max}. Variable \texttt{bias} calculates the number of successive
 ones or zeros read by the automaton, while \texttt{bias\char`_max} is used as a flag
 to indicate that at least two zeros or two ones have been read in a row.
 Finally, property \texttt{prop5} specifies the range of values of variable \texttt{state}.
 
\begin{figure}[tb]
\begin{minipage}[c]{0.35\textwidth}
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{example}
\end{minipage}
\begin{minipage}[c]{0.7\textwidth}
 \begin{Verbatim}[fontsize=\scriptsize]
node top(x : bool; state: int) returns (  );
var
  bias : int;
  prop1, prop2, prop3, prop4, prop5, prop_all : bool;
  bias_max : bool;
let
  bias = 0 -> (if x then 1 else -1) + pre(bias);
  bias_max = false ->
	(bias >= 2 or bias <= -2) or pre(bias_max);
  prop1 = (state = 0 => (bias = 0));
  prop2 = true ->
  	(pre(state = 0) and x) => state = 2;
  prop3 = true ->
  	(pre(state = 0) and not x) => state = 1;
  prop4 = bias_max => state = 3;
  prop5 = state = 0 or state = 1 or state = 2 or state = 3;
  prop_all = prop1 and prop2 and prop3 and prop4 and prop5;
  --%PROPERTY prop_all;
  --%REALIZABLE x;
tel;
 \end{Verbatim}
\end{minipage}
\caption{Automaton and Requirements for running example}
\label{fg:example}
\end{figure}

The \texttt{--\%REALIZABLE} query enables the realizability check that 
succeeds with a k-inductive proof of length $k = 1$. The two corresponding
$\forall\exists$-formulas ($k=0$ for the base check and $k=1$ for the inductive
check) are valid, and thus  \aeval extracts two witnessing Skolem functions
%From this process, we receive two Skolem functions, 
that effectively describe
 assignments to the local variables of the specification, as well as to \texttt{state}
(see Appendix~\ref{app:ex} for the certain formulas).

The Skolem functions are used to construct the final implementation
following the outline provided in Alg.~\ref{alg:synt}. 
It is 135 lines of code, and due to the space constraints we do not
present it here%
\footnote{The implementation for the
example is available at \url{https://arxiv.org/abs/1610.05867} \grigory{isn't it easier to upload just a single C-file somewhere?}.}.
The main idea is to redefine each variable in the model 
as an array of size equal to $k$ and
to use the $k$-th element of each array as the corresponding output of the call
to $k$-th Skolem function. After this initialization process, we use an infinite
loop to assign new values to the element corresponding to the last Skolem
function, to cover the inductive step of the original proof.

\grigory{consider this paragraph. This is based on my chat with Andreas yesterday.}
Recall that the user-defined model specifies explicitly two transitions (via \texttt{prop2} and \texttt{prop3}) only, while the set of implicitly defined transitions (via \texttt{prop1} and \texttt{prop4}) is incomplete.
Indeed, the specification does not have any incoming transition to (\texttt{state = 0}).
In contrast, the synthesized implementation turns all implicit transitions into explicit ones which makes them able to execute, and furthermore adds the missing ones (e.g., from \texttt{state = 1} to \texttt{state = 0}).

\grigory{I suggest to re-run this experiment with prop5 (added yesterday). I'm curious to see the C-implementation.}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "document"
%%% End:
